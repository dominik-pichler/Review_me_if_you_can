{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from pykeen.datasets import PathDataset\n",
    "from pykeen.pipeline import pipeline\n",
    "from neo4j import GraphDatabase\n",
    "from pykeen.triples import TriplesFactory\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "uri = \"bolt://localhost:7687\"  # Update with your Neo4j URI\n",
    "driver = GraphDatabase.driver(uri, auth=(\"neo4j\", \"password\"))  # Update with your credentials\n",
    "\n",
    "uri = \"bolt://localhost:7687\"  # Update with your Neo4j URI\n",
    "driver = GraphDatabase.driver(uri, auth=(\"neo4j\", \"password\"))  # Update with your credentials\n",
    "\n",
    "\n",
    "\n",
    "def fetch_triples():\n",
    "    query = \"\"\"\n",
    "  MATCH (rev:Review)-[:indicates_perceived_cleaning_quality]->(ca:Quality_Indication)\n",
    "    RETURN rev.text AS Review_Text, \n",
    "           \"indicates_perceived_cleaning_quality\",\n",
    "           ca.text as  Quality_Indication\n",
    "    \"\"\"\n",
    "    with driver.session() as session:\n",
    "        result = session.run(query)\n",
    "        return [(record[\"Review_Text\"], \"indicates_perceived_cleaning_quality\", record[\"Quality_Indication\"]) for\n",
    "                record in result]\n",
    "    \n",
    "    \n",
    "triple = fetch_triples()\n",
    "df = pd.DataFrame(triple, columns=['Review_Text', 'indicates_perceived_cleaning_quality','Quality_Indication'])\n",
    "\n",
    "df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pykeen.triples import TriplesFactory\n",
    "\n",
    "# Assuming your dataframe has columns 'subject', 'predicate', 'object'\n",
    "triples_factory = TriplesFactory.from_labeled_triples(\n",
    "    triples=df[['Review_Text', 'indicates_perceived_cleaning_quality', 'Quality_Indication']].values,\n",
    ")\n",
    "\n",
    "training = triples_factory\n",
    "validation = triples_factory\n",
    "testing = triples_factory\n",
    "\n",
    "d=training\n",
    "id_to_entity={v: k for k, v in d.entity_to_id.items()}\n",
    "id_to_relation={v: k for k, v in d.relation_to_id.items()}\n",
    "\n",
    "# Display the first few triples\n",
    "triples_factory.triples"
   ],
   "id": "19db620cbbda88f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pykeen.pipeline import pipeline\n",
    "\n",
    "\n",
    "\n",
    "result = pipeline(\n",
    "    model='TransE',\n",
    "    loss=\"softplus\",\n",
    "    training=training,\n",
    "    testing=testing,\n",
    "    validation=validation,\n",
    "    model_kwargs=dict(embedding_dim=3),  # Increase the embedding dimension\n",
    "    optimizer_kwargs=dict(lr=0.1),  # Adjust the learning rate\n",
    "    training_kwargs=dict(num_epochs=100, use_tqdm_batch=False),  # Increase the number of epochs\n",
    ")\n",
    "\n",
    "# The trained model is stored in the pipeline result\n",
    "model = result.model"
   ],
   "id": "8d00f39ad07ff75a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pykeen.evaluation import RankBasedEvaluator\n",
    "\n",
    "# Create an evaluator\n",
    "evaluator = RankBasedEvaluator()\n",
    "\n",
    "# Evaluate the model\n",
    "metrics = evaluator.evaluate(result.model, testing.mapped_triples, additional_filter_triples=[training.mapped_triples, validation.mapped_triples])\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Hits@1: {metrics.get_metric('hits@1')}\")\n",
    "print(f\"Hits@3: {metrics.get_metric('hits@3')}\")\n",
    "print(f\"Hits@5: {metrics.get_metric('hits@5')}\")\n",
    "print(f\"Hits@10: {metrics.get_metric('hits@10')}\")\n",
    "print(f\"Mean Reciprocal Rank: {metrics.get_metric('mean_reciprocal_rank')}\")"
   ],
   "id": "f4ad2fe88b4cbf41",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pykeen.predict import predict_triples\n",
    "dataset = get_dataset(dataset=\"nations\")\n",
    "pack = predict_triples(model=result.model, triples=dataset.validation) #Hier muss ich einfach alle MÃ¶glichkeiten angeben und bekomme scores"
   ],
   "id": "33c4a6ce3cb8ad7b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def fetch_reviews_without_quality_connection():\n",
    "    pre_predictions = {\"reviews\": {}, \"cleaners\": {}}\n",
    "\n",
    "    query = \"\"\"\n",
    "    // Match all reviews and cleaners\n",
    "    MATCH (rev:Review), (r:Reinigungsmitarbeiter)\n",
    "\n",
    "     // Use OPTIONAL MATCH to find existing connections\n",
    "     OPTIONAL MATCH (rev)-[:HAS_PERCEIVED_CLEANING]->(ca:PerceivedCleaningQuality)-[:INDICATES_CLEANING_QUALITY]->(r)\n",
    "\n",
    "     // Filter out reviews and cleaners that have these connections\n",
    "     WHERE ca IS NULL\n",
    "\n",
    "      RETURN rev.text AS Review_Text, \n",
    "             r.name AS ReinigungsMitarbeiter\n",
    "    \"\"\"\n",
    "    with driver.session() as session:\n",
    "        result = session.run(query)\n",
    "        for record in result:\n",
    "            review_text = record[\"Review_Text\"]\n",
    "            cleaner_name = record[\"ReinigungsMitarbeiter\"]\n",
    "\n",
    "            # Add to predictions dictionary\n",
    "            if review_text not in pre_predictions[\"reviews\"]:\n",
    "                pre_predictions[\"reviews\"][review_text] = []\n",
    "            if cleaner_name not in pre_predictions[\"cleaners\"]:\n",
    "                pre_predictions[\"cleaners\"][cleaner_name] = []\n",
    "\n",
    "            # Add cleaner to the review's list and vice versa\n",
    "            pre_predictions[\"reviews\"][review_text].append(cleaner_name)\n",
    "            pre_predictions[\"cleaners\"][cleaner_name].append(review_text)\n",
    "\n",
    "    # Close the driver connection\n",
    "    driver.close()\n",
    "\n",
    "    return pre_predictions\n",
    "fetch_reviews_without_quality_connection()"
   ],
   "id": "e03c52a5e9483600",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from itertools import product\n",
    "\n",
    "reviews_wo_relation = fetch_reviews_without_quality_connection()\n",
    "\n",
    "df = pd.DataFrame(reviews_wo_relation, columns=['Review_Text'])\n",
    "\n",
    "# List of relations\n",
    "relations = ['A', 'B', 'C']\n",
    "\n",
    "# Generate all combinations of keys with relations\n",
    "combinations = list(product(df['Review_Text'], relations))\n",
    "\n",
    "# Convert combinations to a DataFrame\n",
    "df_combinations = pd.DataFrame(combinations, columns=['key', 'relation'])\n",
    "\n",
    "print(df_combinations)"
   ],
   "id": "245b4cf450e911aa",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
